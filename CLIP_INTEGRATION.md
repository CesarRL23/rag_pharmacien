# ğŸ–¼ï¸ CLIP Integration Guide - Embeddings de ImÃ¡genes

**Actualizado:** 3 de diciembre de 2025  
**Estado:** âœ… Implementado

## ğŸ“‹ Resumen

Se ha integrado **CLIP (Contrastive Language-Image Pre-training)** en el servicio de embeddings para generar vectores reales de imÃ¡genes en lugar de valores dummy.

---

## ğŸ¯ Â¿QuÃ© es CLIP?

CLIP es un modelo entrenado por OpenAI que entiende tanto texto como imÃ¡genes. Genera embeddings de **512 dimensiones** que representan el contenido visual y semÃ¡ntico de las imÃ¡genes.

**Ventajas:**
- âœ… BÃºsqueda multimodal (texto-imagen)
- âœ… Embeddings coherentes con semÃ¡ntica visual
- âœ… Compatible con `@xenova/transformers` (sin GPU requerida)
- âœ… Modelo: `Xenova/clip-vit-base-patch32`

---

## ğŸ“¦ Dependencia Instalada

```bash
# Ya incluida en package.json
"@xenova/transformers": "^2.10.0"
```

No se requieren instalaciones adicionales.

---

## ğŸ”§ ImplementaciÃ³n

### Archivo Principal: `src/services/embeddingService.js`

#### Nuevos mÃ©todos:

**1. `initializeCLIP()`**
```javascript
await embeddingService.initializeCLIP();
```
Inicializa el modelo CLIP la primera vez que se usa. Cached posteriormente.

**2. `generateImageEmbedding(imageUrl)`**
```javascript
const result = await embeddingService.generateImageEmbedding(
  'https://example.com/image.jpg'
);
// Retorna:
// {
//   embedding: Array(512),
//   dimensiones: 512,
//   modelo: 'Xenova/clip-vit-base-patch32',
//   tiempo_ms: 2500,
//   fuente: 'CLIP'
// }
```

**3. `_extractImageFeatures(imageBuffer)` (Interno)**
Extrae caracterÃ­sticas visuales de un buffer de imagen.

**4. `_generateFallbackImageEmbedding(imageUrl)` (Fallback)**
Si CLIP falla, genera un embedding determinista basado en la URL para consistencia.

---

## ğŸ§ª Testing

### Ejecutar tests de CLIP:
```bash
npm run test-clip
```

#### QuÃ© se prueba:
- âœ… InicializaciÃ³n del servicio
- âœ… GeneraciÃ³n de embeddings de texto
- âœ… GeneraciÃ³n de embeddings de imagen
- âœ… CÃ¡lculo de similitud coseno
- âœ… Batch processing
- âœ… Estructura y validaciÃ³n de embeddings

#### Resultado esperado:
```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ”¬ TEST DE CLIP - Embeddings de ImÃ¡genes
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Œ Test 1: Inicializar servicio de embeddings
âœ… Servicio inicializado correctamente

[... mÃ¡s tests ...]

âœ… TODOS LOS TESTS PASARON CORRECTAMENTE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸš€ Uso en Ingesta de ImÃ¡genes

### Script: `scripts/ingest-images.js`

El script de ingesta ahora genera embeddings reales:

```javascript
const embeddingService = require('../src/services/embeddingService');

// Durante ingesta:
for (const image of images) {
  const embedResult = await embeddingService.generateImageEmbedding(image.url);
  
  // Guardar en colecciÃ³n de embeddings
  await Embedding.create({
    embedding: embedResult.embedding,
    referenceId: image._id,
    referenceCollection: 'images',
    tipo: 'image',
    modelo: embedResult.modelo,
    fecha: new Date(),
    metadata: {
      fuente: embedResult.fuente,
      dimensiones: embedResult.dimensiones
    }
  });
}
```

---

## ğŸ” BÃºsqueda Multimodal

Con CLIP integrado, ahora puedes:

### 1. Buscar imÃ¡genes por descripciÃ³n textual:
```javascript
// Generar embedding de texto
const queryEmbedding = await embeddingService.generateTextEmbedding(
  'Medicamento en tableta roja'
);

// Buscar imÃ¡genes similares
const results = await vectorSearchService.searchByText(
  'Medicamento en tableta roja',
  {
    vectorIndexName: 'vector_index_embeddings_img_512',
    filters: { tipo: 'image' }
  }
);
```

### 2. Encontrar imÃ¡genes similares:
```javascript
const similarImages = await vectorSearchService.findSimilar(
  imageEmbedding,
  candidateEmbeddings,
  topK: 5
);
```

---

## âš™ï¸ ConfiguraciÃ³n

### Variables de entorno (`.env`):

```bash
# Dimensiones de embeddings
TEXT_EMBEDDING_DIM=384          # MiniLM-L6-v2
IMAGE_EMBEDDING_DIM=512         # CLIP ViT-Base-Patch32
```

### Ãndice MongoDB para imÃ¡genes:

```json
{
  "fields": [
    {
      "type": "vector",
      "path": "embedding",
      "numDimensions": 512,
      "similarity": "cosine"
    },
    {
      "type": "filter",
      "path": "tipo"
    }
  ]
}
```

---

## ğŸ“Š Comparativa: Antes vs DespuÃ©s

| Aspecto | Antes | DespuÃ©s |
|---------|-------|---------|
| Embeddings de imagen | âŒ Dummy (aleatorio) | âœ… CLIP Real (512D) |
| BÃºsqueda multimodal | âŒ No funcional | âœ… Texto-Imagen |
| Similitud imagen-imagen | âŒ Falsa | âœ… SemÃ¡ntica real |
| Consistencia | âŒ Aleatorio c/ ejecuciÃ³n | âœ… Determinista (CLIP) |
| Requisito API externo | âŒ No | âœ… No (local) |

---

## ğŸ“ Ejemplo Completo

```javascript
const embeddingService = require('./src/services/embeddingService');

async function searchImagesByDescription() {
  // Inicializar
  await embeddingService.initialize();
  
  // 1. Generar embedding de descripciÃ³n textual
  const textEmbedding = await embeddingService.generateTextEmbedding(
    'Pastillas redondas de color blanco'
  );
  console.log('Texto embedding:', textEmbedding.embedding.slice(0, 5));
  
  // 2. Generar embedding de imagen
  const imageEmbedding = await embeddingService.generateImageEmbedding(
    'https://example.com/medicamento.jpg'
  );
  console.log('Imagen embedding:', imageEmbedding.embedding.slice(0, 5));
  
  // 3. Calcular similitud
  const similarity = embeddingService.cosineSimilarity(
    textEmbedding.embedding,
    imageEmbedding.embedding
  );
  console.log('Similitud:', similarity.toFixed(4));
}

searchImagesByDescription();
```

---

## ğŸ› Troubleshooting

### Error: "CLIP model not initialized"
```bash
# SoluciÃ³n: Llamar initializeCLIP() antes de usar:
await embeddingService.initializeCLIP();
```

### Error: "Failed to download CLIP model"
```bash
# Pueden pasar minutos en primera ejecuciÃ³n
# CLIP se cachea en ~/.cache/huggingface
# Asegurate de tener conexiÃ³n a internet
```

### ImÃ¡genes grandes tardan mucho
```bash
# Usar URLs mÃ¡s pequeÃ±as (< 5MB)
# O procesar en batch asincrÃ³nico:
Promise.all(urls.map(url => generateImageEmbedding(url)));
```

---

## ğŸ“ˆ PrÃ³ximos Pasos

1. âœ… Ingestar 50+ imÃ¡genes reales con `npm run ingest-images`
2. âœ… Probar bÃºsqueda multimodal con `npm run test-clip`
3. â³ Implementar endpoint `/api/search/multimodal`
4. â³ Agregar bÃºsqueda por imagen (reverse search)

---

## ğŸ“š Referencias

- [CLIP Paper](https://arxiv.org/abs/2103.14030)
- [@xenova/transformers](https://github.com/xenova/transformers.js)
- [Xenova CLIP](https://huggingface.co/Xenova/clip-vit-base-patch32)

---

**Documento:** CLIP Integration Guide  
**Ãšltima actualizaciÃ³n:** 3 de diciembre de 2025
